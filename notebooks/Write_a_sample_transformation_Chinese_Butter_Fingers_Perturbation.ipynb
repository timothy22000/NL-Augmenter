{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drfP193NQSZ6"
   },
   "source": [
    "<a href =\"https://colab.research.google.com/github/GEM-benchmark/NL-Augmenter/blob/main/notebooks/Write_a_sample_transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMrWwwGdP4wO"
   },
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "\n",
    "\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2QcAG8bThqq"
   },
   "source": [
    "# NL-Augmenter Colab example \n",
    "\n",
    "  * Play with an existing **transformation** \n",
    "    * Write your own **transformation** \n",
    "  * Play with an existing **filter**  \n",
    "    * Write your own **filter**         \n",
    "\n",
    "Total running time: ~10 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI_4yHCIAvQx"
   },
   "source": [
    "## Install NL-Augmenter from GitHub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkv4WSJsI7YV",
    "outputId": "f16ad930-bbb2-4237-ab3a-5f7b8ea8f04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'NL-Augmenter'...\n",
      "remote: Enumerating objects: 1726, done.\u001b[K\n",
      "remote: Counting objects: 100% (680/680), done.\u001b[K\n",
      "remote: Compressing objects: 100% (401/401), done.\u001b[K\n",
      "remote: Total 1726 (delta 381), reused 459 (delta 263), pack-reused 1046\u001b[K\n",
      "Receiving objects: 100% (1726/1726), 363.57 KiB | 15.81 MiB/s, done.\n",
      "Resolving deltas: 100% (1016/1016), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://www.github.com/GEM-benchmark/NL-Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9KCH1qpHjDo",
    "outputId": "2376035b-de27-4339-c946-41ac38cbd4e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'NL-Augmenter'\n",
      "/Users/admintmun/dev/NL-Augmenter/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd NL-Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admintmun/dev/NL-Augmenter\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMiID0kSE_Qf",
    "outputId": "802e7ccb-71fe-42f2-e31b-cf541a643353"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkdXQrzKR0zY"
   },
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJcZGbR7JVFt",
    "outputId": "991e3d98-7e75-4129-a41a-2a04e1ffbd94"
   },
   "outputs": [],
   "source": [
    "from transformations.butter_fingers_perturbation.transformation import ButterFingersPerturbation\n",
    "from transformations.change_person_named_entities.transformation import ChangePersonNamedEntities\n",
    "from transformations.replace_numerical_values.transformation import ReplaceNumericalValues\n",
    "from interfaces.SentenceOperation import SentenceOperation\n",
    "from interfaces.QuestionAnswerOperation import QuestionAnswerOperation\n",
    "from evaluation.evaluation_engine import evaluate, execute_model\n",
    "from tasks.TaskTypes import TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kT8V407QBFYz"
   },
   "source": [
    "## Play with some existing transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZfjp0toJdHh",
    "outputId": "00bb37e0-0122-4496-8e84-c1b6bc06f1d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jasln wants to move back to India by the end od next year.',\n",
       " 'Jason wants to move back to India by thx end of ntxt year.',\n",
       " 'Jason wants to move back no India by tht end od next yeac.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = ButterFingersPerturbation(max_outputs=3)\n",
    "t1.generate(\"Jason wants to move back to India by the end of next year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_o9ktK9JwKs",
    "outputId": "c611655f-df1c-4577-f837-3ae1156ba95e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Austin wants to move back to India by the end of next year.']"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = ChangePersonNamedEntities(max_outputs=2)\n",
    "t2.generate(\"Jason wants to move back to India by the end of next year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1khspY1AH_j",
    "outputId": "a88fbfb5-a788-4df2-c442-e386d6de8c1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Jason's 8 sisters want to move back to India\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = ReplaceNumericalValues(max_outputs=1)\n",
    "t3.generate(\"Jason's 3 sisters want to move back to India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing new transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations.chinese_butter_fingers_perturbation import ChineseButterFingersPerturbation\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/admintmun/dev/NL-Augmenter/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_perturbation = ChineseButterFingersPerturbation(prob=0.2, max_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Common Word List\n",
      "协邪胁斜谐携鞋泄泻屑械卸谢懈蟹写些楔歇蝎\n",
      "From Full Character List\n",
      "协邪胁斜谐携鞋泄泻屑械卸谢懈蟹写些楔歇蝎\n",
      "From Common Word List\n",
      "儿而贰二尔耳饵\n",
      "From Full Character List\n",
      "儿而贰二尔耳饵\n",
      "From Common Word List\n",
      "蛮馒瞒曼幔慢漫蔓满\n",
      "From Full Character List\n",
      "蛮馒瞒曼幔慢漫蔓满\n",
      "From Common Word List\n",
      "匠降酱讲奖桨蒋江姜将浆僵缰疆\n",
      "From Full Character List\n",
      "匠降酱讲奖桨蒋江姜将浆僵缰疆\n",
      "From Common Word List\n",
      "防妨房肪放仿访纺方坊芳\n",
      "From Full Character List\n",
      "防妨房肪放仿访纺方坊芳\n",
      "From Common Word List\n",
      "文纹闻蚊问吻紊稳瘟温\n",
      "From Full Character List\n",
      "文纹闻蚊问吻紊稳瘟温\n",
      "From Common Word List\n",
      "仲众重肿种终盅钟衷中忠\n",
      "From Full Character List\n",
      "仲众重肿种终盅钟衷中忠\n",
      "From Common Word List\n",
      "国过裹果郭锅\n",
      "From Full Character List\n",
      "国过裹果郭锅\n",
      "From Common Word List\n",
      "甜填田恬舔天添\n",
      "From Full Character List\n",
      "甜填田恬舔天添\n",
      "From Common Word List\n",
      "晋浸禁尽劲近进仅紧谨锦筋襟巾今斤金津\n",
      "From Full Character List\n",
      "晋浸禁尽劲近进仅紧谨锦筋襟巾今斤金津\n",
      "From Common Word List\n",
      "\n",
      "From Full Character List\n",
      "\n",
      "From Common Word List\n",
      "仲众重肿种终盅钟衷中忠\n",
      "From Full Character List\n",
      "仲众重肿种终盅钟衷中忠\n",
      "From Common Word List\n",
      "国过裹果郭锅\n",
      "From Full Character List\n",
      "国过裹果郭锅\n",
      "From Common Word List\n",
      "外歪\n",
      "From Full Character List\n",
      "外歪\n",
      "From Common Word List\n",
      "嚼叫轿较教窖酵矫脚搅剿缴角狡绞饺蕉礁浇骄胶椒焦交郊娇\n",
      "From Full Character List\n",
      "嚼叫轿较教窖酵矫脚搅剿缴角狡绞饺蕉礁浇骄胶椒焦交郊娇\n",
      "From Common Word List\n",
      "不布步怖部埠簿补哺捕\n",
      "From Full Character List\n",
      "不布步怖部埠簿补哺捕\n",
      "From Common Word List\n",
      "竹烛逐贮住助注驻柱祝著蛀筑铸煮嘱主拄蛛朱株珠诸猪\n",
      "From Full Character List\n",
      "竹烛逐贮住助注驻柱祝著蛀筑铸煮嘱主拄蛛朱株珠诸猪\n",
      "From Common Word List\n",
      "冠灌贯惯罐馆管棺关观官\n",
      "From Full Character List\n",
      "冠灌贯惯罐馆管棺关观官\n",
      "From Common Word List\n",
      "仲众重肿种终盅钟衷中忠\n",
      "From Full Character List\n",
      "仲众重肿种终盅钟衷中忠\n",
      "From Common Word List\n",
      "媒楣煤没枚玫眉梅霉妹昧媚每美\n",
      "From Full Character List\n",
      "媒楣煤没枚玫眉梅霉妹昧媚每美\n",
      "From Common Word List\n",
      "冠灌贯惯罐馆管棺关观官\n",
      "From Full Character List\n",
      "冠灌贯惯罐馆管棺关观官\n",
      "From Common Word List\n",
      "习席袭媳戏系细隙洗徙铣喜蟋嬉膝悉惜晰溪锡熄熙犀稀夕西吸希昔析息牺\n",
      "From Full Character List\n",
      "习席袭媳戏系细隙洗徙铣喜蟋嬉膝悉惜晰溪锡熄熙犀稀夕西吸希昔析息牺\n",
      "From Common Word List\n",
      "的得德\n",
      "From Full Character List\n",
      "的得德\n",
      "From Common Word List\n",
      "扶芙拂服俘浮符袱幅伏凫福辐蝠父付妇负附咐复傅赴富副覆赋缚腹腐辅抚甫府斧俯肤麸孵敷夫\n",
      "From Full Character List\n",
      "扶芙拂服俘浮符袱幅伏凫福辐蝠父付妇负附咐复傅赴富副覆赋缚腹腐辅抚甫府斧俯肤麸孵敷夫\n",
      "From Common Word List\n",
      "不布步怖部埠簿补哺捕\n",
      "From Full Character List\n",
      "不布步怖部埠簿补哺捕\n",
      "From Common Word List\n",
      "肠尝偿常长畅倡唱厂场敞昌猖\n",
      "From Full Character List\n",
      "肠尝偿常长畅倡唱厂场敞昌猖\n",
      "From Common Word List\n",
      "协邪胁斜谐携鞋泄泻屑械卸谢懈蟹写些楔歇蝎\n",
      "From Full Character List\n",
      "协邪胁斜谐携鞋泄泻屑械卸谢懈蟹写些楔歇蝎\n",
      "From Common Word List\n",
      "逢缝冯凤奉讽锋蜂丰风峰枫封疯\n",
      "From Full Character List\n",
      "逢缝冯凤奉讽锋蜂丰风峰枫封疯\n",
      "From Common Word List\n",
      "匠降酱讲奖桨蒋江姜将浆僵缰疆\n",
      "From Full Character List\n",
      "匠降酱讲奖桨蒋江姜将浆僵缰疆\n",
      "From Common Word List\n",
      "禾合何和河核荷盒褐赫鹤贺喝呵\n",
      "From Full Character List\n",
      "禾合何和河核荷盒褐赫鹤贺喝呵\n",
      "From Common Word List\n",
      "踏蹋塔塌他它她\n",
      "From Full Character List\n",
      "踏蹋塔塌他它她\n",
      "From Common Word List\n",
      "回茴蛔汇会讳贿晦秽惠慧绘诲毁悔徽灰恢挥辉\n",
      "From Full Character List\n",
      "回茴蛔汇会讳贿晦秽惠慧绘诲毁悔徽灰恢挥辉\n",
      "From Common Word List\n",
      "坛昙谈痰谭潭檀叹炭碳探坦袒毯摊滩贪瘫\n",
      "From Full Character List\n",
      "坛昙谈痰谭潭檀叹炭碳探坦袒毯摊滩贪瘫\n",
      "From Common Word List\n",
      "\n",
      "From Full Character List\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['懈尔幔桨肪问众裹舔劲，忠郭歪胶哺主关众眉官牺得复布场谐蜂桨盒他汇瘫.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_perturbation.generate(\"谢尔曼将访问中国天津，中国外交部主管中美关系的副部长谢峰将和她会谈.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_perturbation = ChineseButterFingersPerturbation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/vd/3vrnjbd50935tzjj4872zb480000gq/T/jieba.cache\n",
      "Loading model cost 0.594 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'perturb_word': '谢尔曼', 'similar_pinyin_words': []}, {'perturb_word': '将', 'similar_pinyin_words': ['匠', '降', '酱', '讲', '奖', '桨', '蒋', '江', '姜', '浆', '僵', '缰', '疆']}, {'perturb_word': '访问', 'similar_pinyin_words': ['方闻', '妨紊', '访闻']}, {'perturb_word': '中国', 'similar_pinyin_words': []}, {'perturb_word': '天津', 'similar_pinyin_words': []}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '中国外交部', 'similar_pinyin_words': []}, {'perturb_word': '主管', 'similar_pinyin_words': ['朱观']}, {'perturb_word': '中美关系', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '副', 'similar_pinyin_words': ['扶', '芙', '拂', '服', '俘', '浮', '符', '袱', '幅', '伏', '凫', '福', '辐', '蝠', '父', '付', '妇', '负', '附', '咐', '复', '傅', '赴', '富', '覆', '赋', '缚', '腹', '腐', '辅', '抚', '甫', '府', '斧', '俯', '肤', '麸', '孵', '敷', '夫']}, {'perturb_word': '部长', 'similar_pinyin_words': ['不彰', '布帐', '步鄣', '步帐', '步障', '部帐', '簿帐']}, {'perturb_word': '谢峰', 'similar_pinyin_words': []}, {'perturb_word': '将', 'similar_pinyin_words': ['匠', '降', '酱', '讲', '奖', '桨', '蒋', '江', '姜', '浆', '僵', '缰', '疆']}, {'perturb_word': '和', 'similar_pinyin_words': ['禾', '合', '何', '河', '核', '荷', '盒', '褐', '赫', '鹤', '贺', '喝', '呵']}, {'perturb_word': '她', 'similar_pinyin_words': ['踏', '蹋', '塔', '塌', '他', '它']}, {'perturb_word': '会谈', 'similar_pinyin_words': ['回弹', '灰炭', '诙谈', '回弹', '回滩', '悔叹', '秽谈']}, {'perturb_word': '.', 'similar_pinyin_words': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['谢尔曼将访问中国天津，中国外交部朱观中美关系的副部长谢峰蒋和她回滩.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_perturbation.generate(\"谢尔曼将访问中国天津，中国外交部主管中美关系的副部长谢峰将和她会谈.\")\n",
    "# chinese_perturbation.generate(\"燮\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'perturb_word': '本意', 'similar_pinyin_words': ['奔轶', '奔逸', '犇佚', '犇逸', '本义', '本议', '本谊', '坌溢']}, {'perturb_word': '是', 'similar_pinyin_words': ['匙', '时', '十', '什', '石', '识', '实', '拾', '蚀', '食', '誓', '释', '嗜', '柿', '逝', '适', '式', '士', '氏', '世', '市', '示', '事', '侍', '势', '视', '试', '饰', '室', '恃', '拭', '史', '矢', '使', '始', '驶', '尸', '失', '师', '虱', '诗', '施', '狮', '湿']}, {'perturb_word': '指词', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '起源', 'similar_pinyin_words': ['栖园', '奇冤', '奇缘', '期愿']}, {'perturb_word': '义', 'similar_pinyin_words': ['宜', '仪', '夷', '姨', '胰', '移', '遗', '疑', '疫', '绎', '奕', '译', '邑', '易', '意', '溢', '益', '谊', '逸', '翼', '肄', '毅', '亿', '忆', '艺', '议', '亦', '屹', '异', '役', '抑', '蚁', '倚', '椅', '乙', '已', '以', '伊', '衣', '医', '依', '壹', '揖', '一']}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '即词', 'similar_pinyin_words': ['赍刺', '即此', '季次', '寄词', '寄辞', '激辞', '急辞', '稷祠', '积次', '祭祠', '击刺', '棘茨', '藉词', '赍赐', '激刺', '羁雌', '集辞', '记词', '棘刺']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '最初', 'similar_pinyin_words': []}, {'perturb_word': '意义', 'similar_pinyin_words': ['一医']}, {'perturb_word': '。', 'similar_pinyin_words': []}, {'perturb_word': '引申义', 'similar_pinyin_words': []}, {'perturb_word': '是', 'similar_pinyin_words': ['匙', '时', '十', '什', '石', '识', '实', '拾', '蚀', '食', '誓', '释', '嗜', '柿', '逝', '适', '式', '士', '氏', '世', '市', '示', '事', '侍', '势', '视', '试', '饰', '室', '恃', '拭', '史', '矢', '使', '始', '驶', '尸', '失', '师', '虱', '诗', '施', '狮', '湿']}, {'perturb_word': '由', 'similar_pinyin_words': ['尤', '犹', '邮', '油', '游', '又', '右', '幼', '佑', '诱', '友', '有', '幽', '悠', '优', '忧']}, {'perturb_word': '词', 'similar_pinyin_words': ['祠', '慈', '辞', '磁', '雌', '瓷', '次', '刺', '赐', '此']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '本意', 'similar_pinyin_words': ['奔轶', '奔逸', '犇佚', '犇逸', '本义', '本议', '本谊', '坌溢']}, {'perturb_word': '引申', 'similar_pinyin_words': []}, {'perturb_word': '出来', 'similar_pinyin_words': ['初来', '楚濑']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '并', 'similar_pinyin_words': ['病', '丙', '秉', '柄', '饼', '禀', '冰', '兵']}, {'perturb_word': '经过', 'similar_pinyin_words': ['京国', '荆国', '凈国', '精果', '井椁', '经国']}, {'perturb_word': '推演', 'similar_pinyin_words': []}, {'perturb_word': '发展', 'similar_pinyin_words': ['发战']}, {'perturb_word': '而', 'similar_pinyin_words': ['儿', '贰', '二', '尔', '耳', '饵']}, {'perturb_word': '产生', 'similar_pinyin_words': ['缠声', '颤声']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '意义', 'similar_pinyin_words': ['一医']}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['本意始指词的起源义，即词的最初一医。引申义驶由词得本谊引申出来的并经过推演发展而缠声得意义']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_perturbation.generate(\"本意是指词的起源义，即词的最初意义。引申义是由词的本意引申出来的并经过推演发展而产生的意义\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'perturb_word': '汉字', 'similar_pinyin_words': ['蚶子', '酣紫', '酣恣', '憨子', '含姿', '含渍', '涵渍', '寒姿', '韩子', '汉子', '汗渍']}, {'perturb_word': '是', 'similar_pinyin_words': ['匙', '时', '十', '什', '石', '识', '实', '拾', '蚀', '食', '誓', '释', '嗜', '柿', '逝', '适', '式', '士', '氏', '世', '市', '示', '事', '侍', '势', '视', '试', '饰', '室', '恃', '拭', '史', '矢', '使', '始', '驶', '尸', '失', '师', '虱', '诗', '施', '狮', '湿']}, {'perturb_word': '语素', 'similar_pinyin_words': []}, {'perturb_word': '文字', 'similar_pinyin_words': []}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '总数', 'similar_pinyin_words': ['综述']}, {'perturb_word': '非常', 'similar_pinyin_words': ['肥肠', '腓肠', '肥肠', '腓肠', '棐常', '肺肠']}, {'perturb_word': '庞大', 'similar_pinyin_words': []}, {'perturb_word': '。', 'similar_pinyin_words': []}, {'perturb_word': '汉字', 'similar_pinyin_words': ['蚶子', '酣紫', '酣恣', '憨子', '含姿', '含渍', '涵渍', '寒姿', '韩子', '汉子', '汗渍']}, {'perturb_word': '总共', 'similar_pinyin_words': []}, {'perturb_word': '有', 'similar_pinyin_words': ['尤', '由', '犹', '邮', '油', '游', '又', '右', '幼', '佑', '诱', '友', '幽', '悠', '优', '忧']}, {'perturb_word': '多少', 'similar_pinyin_words': []}, {'perturb_word': '字', 'similar_pinyin_words': ['自', '姊', '紫', '滓', '籽', '子', '咨', '姿', '资', '滋', '吱']}, {'perturb_word': '？', 'similar_pinyin_words': []}, {'perturb_word': '到', 'similar_pinyin_words': ['盗', '道', '稻', '悼', '蹈', '捣', '祷', '导', '岛', '倒', '叨', '刀']}, {'perturb_word': '目前为止', 'similar_pinyin_words': []}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '恐怕', 'similar_pinyin_words': []}, {'perturb_word': '没', 'similar_pinyin_words': ['媒', '楣', '煤', '枚', '玫', '眉', '梅', '霉', '妹', '昧', '媚', '每', '美']}, {'perturb_word': '人', 'similar_pinyin_words': ['仁', '刃', '认', '任', '纫', '韧', '忍']}, {'perturb_word': '能够', 'similar_pinyin_words': []}, {'perturb_word': '答得', 'similar_pinyin_words': ['大德', '达德', '达德', '大德']}, {'perturb_word': '上来', 'similar_pinyin_words': []}, {'perturb_word': '精确', 'similar_pinyin_words': ['颈缺', '静悫', '京阙', '惊鹊', '精塙']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '数字', 'similar_pinyin_words': []}, {'perturb_word': '。', 'similar_pinyin_words': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['酣紫是语素文字，总数非常庞大。汉字总共有多少字？到目前为止，恐怕美人能够大德上来精确的数字。']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chinese_perturbation.generate(\"汉字是语素文字，总数非常庞大。汉字总共有多少字？到目前为止，恐怕没人能够答得上来精确的数字。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'perturb_word': '恰当', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '运用', 'similar_pinyin_words': []}, {'perturb_word': '反义词', 'similar_pinyin_words': []}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '可以', 'similar_pinyin_words': ['柯怡']}, {'perturb_word': '形成', 'similar_pinyin_words': ['星城', '行成', '行城', '行程', '行塍', '行秤']}, {'perturb_word': '鲜明', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '对比', 'similar_pinyin_words': ['对笔', '怼笔']}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '把', 'similar_pinyin_words': ['跋', '拔', '坝', '爸', '罢', '霸', '靶', '八', '巴', '叭', '扒', '吧', '芭', '疤', '捌', '笆']}, {'perturb_word': '事物', 'similar_pinyin_words': ['石屋']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '特点', 'similar_pinyin_words': []}, {'perturb_word': '表达', 'similar_pinyin_words': []}, {'perturb_word': '得', 'similar_pinyin_words': ['的', '德']}, {'perturb_word': '更', 'similar_pinyin_words': ['耿', '梗', '埂', '耕', '羹']}, {'perturb_word': '充分', 'similar_pinyin_words': ['充份', '崇坟']}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '给', 'similar_pinyin_words': []}, {'perturb_word': '人', 'similar_pinyin_words': ['仁', '刃', '认', '任', '纫', '韧', '忍']}, {'perturb_word': '留下', 'similar_pinyin_words': ['溜下']}, {'perturb_word': '深刻', 'similar_pinyin_words': []}, {'perturb_word': '难忘', 'similar_pinyin_words': ['南网', '南望', '南旺']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '印象', 'similar_pinyin_words': []}, {'perturb_word': '。', 'similar_pinyin_words': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['恰当的运用反义词，可以形成鲜明的对比，把石屋的特点表达得更充分，给人溜下深刻难忘的印象。']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_perturbation.generate(\"恰当的运用反义词，可以形成鲜明的对比，把事物的特点表达得更充分，给人留下深刻难忘的印象。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'perturb_word': '随着', 'similar_pinyin_words': []}, {'perturb_word': '两个', 'similar_pinyin_words': []}, {'perturb_word': '遗迹', 'similar_pinyin_words': ['易基', '义集', '伊籍']}, {'perturb_word': '文明', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '发展', 'similar_pinyin_words': ['发战']}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '他们', 'similar_pinyin_words': []}, {'perturb_word': '终于', 'similar_pinyin_words': ['钟毓']}, {'perturb_word': '开始', 'similar_pinyin_words': []}, {'perturb_word': '了', 'similar_pinyin_words': ['乐', '勒']}, {'perturb_word': '争斗', 'similar_pinyin_words': ['正斗']}, {'perturb_word': '。', 'similar_pinyin_words': []}, {'perturb_word': '遗迹', 'similar_pinyin_words': ['易基', '义集', '伊籍']}, {'perturb_word': '之间', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '能量', 'similar_pinyin_words': []}, {'perturb_word': '冲突', 'similar_pinyin_words': ['冲途']}, {'perturb_word': '是', 'similar_pinyin_words': ['匙', '时', '十', '什', '石', '识', '实', '拾', '蚀', '食', '誓', '释', '嗜', '柿', '逝', '适', '式', '士', '氏', '世', '市', '示', '事', '侍', '势', '视', '试', '饰', '室', '恃', '拭', '史', '矢', '使', '始', '驶', '尸', '失', '师', '虱', '诗', '施', '狮', '湿']}, {'perturb_word': '战争', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '导火索', 'similar_pinyin_words': []}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '因为', 'similar_pinyin_words': []}, {'perturb_word': '一方', 'similar_pinyin_words': ['乙方']}, {'perturb_word': '出现', 'similar_pinyin_words': ['滁县', '出险', '出线', '初弦', '初献', '楚鲜', '楚弦', '楚羡', '触陷']}, {'perturb_word': '，', 'similar_pinyin_words': []}, {'perturb_word': '另一方', 'similar_pinyin_words': []}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '遗迹', 'similar_pinyin_words': ['易基', '义集', '伊籍']}, {'perturb_word': '能量', 'similar_pinyin_words': []}, {'perturb_word': '就', 'similar_pinyin_words': ['旧', '臼', '疚', '救', '舅', '韭', '酒', '灸', '玖', '九', '久', '纠', '究', '鸠', '揪']}, {'perturb_word': '会', 'similar_pinyin_words': ['回', '茴', '蛔', '汇', '讳', '贿', '晦', '秽', '惠', '慧', '绘', '诲', '毁', '悔', '徽', '灰', '恢', '挥', '辉']}, {'perturb_word': '相应', 'similar_pinyin_words': ['香营', '项英']}, {'perturb_word': '的', 'similar_pinyin_words': ['得', '德']}, {'perturb_word': '颓落', 'similar_pinyin_words': []}, {'perturb_word': '。', 'similar_pinyin_words': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['随着两个遗迹文明的发展，他们终于开始了正斗。遗迹之间的能量冲突驶战争德导火索，因为一方出现，另一方的伊籍能量就挥相应德颓落。']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_perturbation.generate(\"随着两个遗迹文明的发展，他们终于开始了争斗。遗迹之间的能量冲突是战争的导火索，因为一方出现，另一方的遗迹能量就会相应的颓落。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/admintmun/dev/NL-Augmenter/transformations/chinese_butter_fingers_perturbation/chinese_word.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vd/3vrnjbd50935tzjj4872zb480000gq/T/ipykernel_36353/191661295.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"阿鼻\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mperturb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChineseButterFingersPerturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnewtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchinese_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchinese_words_database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/NL-Augmenter/transformations/chinese_butter_fingers_perturbation/transformation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, seed, max_outputs, prob, rare_word_prob, consider_tone)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchar_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchinese_character_database\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconsider_tone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpinyin_for_char_to_be_perturbed\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mchar_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pinyin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0mchars_with_similar_pinyin\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchar_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/NL-Augmenter/transformations/chinese_butter_fingers_perturbation/transformation.py\u001b[0m in \u001b[0;36mload_chinese_character_data_into_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mword_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchinese_words_database\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mperturb_word_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/admintmun/dev/NL-Augmenter/transformations/chinese_butter_fingers_perturbation/chinese_word.json'"
     ]
    }
   ],
   "source": [
    "text = \"阿鼻\"\n",
    "\n",
    "perturb = ChineseButterFingersPerturbation()\n",
    "newtext = perturb.generate(text)\n",
    "chinese_words = perturb.chinese_words_database\n",
    "print(perturb.chinese_words_database)\n",
    "output = jieba.lcut(text)\n",
    "# print(output)\n",
    "\n",
    "similar_word_pinyin_list = []\n",
    "for perturb_word in output:\n",
    "    perturb_word_len = len(perturb_word)\n",
    "    for i in range(len(chinese_words)):\n",
    "        word_dict = chinese_words[i]\n",
    "        word = word_dict['word']\n",
    "        if(len(word) == perturb_word_len):\n",
    "            perturb_word_pinyins = pypinyin.pinyin(perturb_word)\n",
    "            perturb_word_pinyins_flatten = [item for pinyin in perturb_word_pinyins for item in pinyin]\n",
    "            perturb_word_pinyins_string = ''.join(perturb_word_pinyins_flatten)\n",
    "            word_pinyins = pypinyin.pinyin(word)\n",
    "            word_pinyins_flatten = [item for pinyin in word_pinyins for item in pinyin]\n",
    "            word_pinyins_string = ''.join(word_pinyins_flatten)\n",
    "            same_pinyin = [perturb_word_pinyin for perturb_word_pinyin, word_pinyin  in zip(perturb_word_pinyins_flatten, word_pinyins_flatten) if perturb_word_pinyin == word_pinyin]\n",
    "\n",
    "            perturb_word_pinyins_string_no_tone = u.unidecode(perturb_word_pinyins_string)\n",
    "            word_pinyins_string_no_tone = u.unidecode(word_pinyins_string)\n",
    "\n",
    "            print(perturb_word_pinyins_string_no_tone)\n",
    "            print(word_pinyins_string_no_tone)\n",
    "            if (perturb_word_pinyins_string_no_tone== word_pinyins_string_no_tone):\n",
    "                similar_word_pinyin_list.append(word)\n",
    "\n",
    "        print(similar_word_pinyin_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_add = SentenceAdditions(max_outputs=3, max_length=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Historically, the uncertainty principle has been confused with a related effect in physics, called the observer effect, which notes that measurements of certain systems cannot be made without affecting the system, that is, without changing something in a system. To the extent that observation affects the system, measurement is not an independent action to be made. But it is a possible',\n",
       " 'Historically, the uncertainty principle has been confused with a related effect in physics, called the observer effect, which notes that measurements of certain systems cannot be made without affecting the system, that is, without changing something in a system. The difference, in contrast, is that the uncertainty principle says that no amount of uncertainty in the measurement will affect the meaning',\n",
       " 'Historically, the uncertainty principle has been confused with a related effect in physics, called the observer effect, which notes that measurements of certain systems cannot be made without affecting the system, that is, without changing something in a system. This suggests that the uncertainty principle is a fundamental feature of scientific knowledge. However, since the 1970s, the problem with']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_add.generate(\"Historically, the uncertainty principle has been confused with a related effect in physics, called the observer effect, which notes that measurements of certain systems cannot be made without affecting the system, that is, without changing something in a system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_add = SentenceAdditions(max_outputs=1, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['John was not the person that I had imagined. I had thought that he would have strong qualities. I think I knew that I wanted to do something']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_add.generate(\"John was not the person that I had imagined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Trinity Medical Imaging is one of the foremost providers of private nuclear medicine imaging in London and Surrey. We work with someof the finest nuclear medicine consultants from a wide variety of specialist fields, attracted from London's major teaching hospitals. Trinity Medical Imaging has won awards for excellence from the Royal College of Radiologists, The Royal College of Surgeons,\",\n",
       " \"Trinity Medical Imaging is one of the foremost providers of private nuclear medicine imaging in London and Surrey. We work with someof the finest nuclear medicine consultants from a wide variety of specialist fields, attracted from London's major teaching hospitals. We are also a leading provider for a wide range of diagnostic and clinical imaging tests and procedures, including brain tumour scans\",\n",
       " \"Trinity Medical Imaging is one of the foremost providers of private nuclear medicine imaging in London and Surrey. We work with someof the finest nuclear medicine consultants from a wide variety of specialist fields, attracted from London's major teaching hospitals. This enables us to offer unique solutions and specialist training to our cancer patients, as well as to their families.\\n\\n\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_add.generate('Trinity Medical Imaging is one of the foremost providers of private nuclear medicine imaging in London and Surrey. We work with someof the finest nuclear medicine consultants from a wide variety of specialist fields, attracted from London\\'s major teaching hospitals.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading <imdb> dataset to evaluate <aychang/roberta-base-imdb> model.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b52365e35ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexecute_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentenceAdditions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TEXT_CLASSIFICATION\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage_of_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/NL-Augmenter/evaluation/evaluation_engine.py\u001b[0m in \u001b[0;36mexecute_model\u001b[0;34m(implementation, task_type, locale, model_name, dataset, percentage_of_examples, evaluate_filter)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"test[:{percentage_of_examples}%]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             )\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/NL-Augmenter/evaluation/evaluate_text_classification.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(operation, evaluate_filter, model_name, dataset_name, split, batch_size, is_cuda)\u001b[0m\n\u001b[1;32m     92\u001b[0m     text_classification_pipeline = pipeline(\n\u001b[1;32m     93\u001b[0m         \u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         device=0 if is_cuda else -1)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"[{split.split('[')[-1]}\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"[\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_extractor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, return_all_scores, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         self.check_model_type(\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, modelcard, framework, task, args_parser, device, binary_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# Special handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update config with task specific parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/siamese_network_test/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "execute_model(SentenceAdditions, \"TEXT_CLASSIFICATION\", percentage_of_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2CB0LRbBWST"
   },
   "source": [
    "## Define a simple transformation\n",
    "Let's define a very basic transformation which just uppercases the sentence. \n",
    "\n",
    "This transformation could be used for many [tasks](https://github.com/GEM-benchmark/NL-Augmenter/blob/add_filters_for_contrast_sets/tasks/TaskTypes.py) including text classification and generation. So, we need to populate the `tasks` variable to `[TaskType.TEXT_CLASSIFICATION, TaskType.TEXT_TO_TEXT_GENERATION]`. That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BymdwQ3PJzg7"
   },
   "outputs": [],
   "source": [
    "class MySimpleTransformation(SentenceOperation):\n",
    "  tasks = [TaskType.TEXT_CLASSIFICATION, TaskType.TEXT_TO_TEXT_GENERATION]\n",
    "  languages = [\"en\"]\n",
    "  \n",
    "  def generate(self, sentence):\n",
    "    return [sentence.upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkqtwqYlUWXV"
   },
   "outputs": [],
   "source": [
    "my_transformation = MySimpleTransformation() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbbSJxJ8UbVz",
    "outputId": "9e1a3098-0899-4084-c88c-50d8a54d0193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"JOHN WAS N'T THE PERSON I HAD N'T IMAGINED.\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_transformation.generate(\"John was n't the person I had n't imagined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8682Ql9GOP0"
   },
   "source": [
    "\n",
    "Obviously this can barely be called a transformation. What could this really achieve? Duh. \n",
    "So, let's quickly compare the performance of a trained text classifier on a common test set, and a test set with MySimpleTransformation applied (or also called as a pertubed set) with this one line of code. And you need to hold your breadth for around 5 minutes!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJlW0WnrVU0n",
    "outputId": "616b175d-7dd7-4999-afbe-6ac2bfa4bf72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading <imdb> dataset to evaluate <aychang/roberta-base-imdb> model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the performance of the model aychang/roberta-base-imdb on the test[:1%] split of the imdb dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 226670.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on this subset = 95.6\n",
      "Applying transformation:\n",
      "Here is the performance of the model on the transformed set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on this subset = 89.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 95.6,\n",
       " 'dataset_name': 'imdb',\n",
       " 'model_name': 'aychang/roberta-base-imdb',\n",
       " 'no_of_examples': 250,\n",
       " 'pt_accuracy': 89.2,\n",
       " 'split': 'test[:1%]'}"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_model(MySimpleTransformation, \"TEXT_CLASSIFICATION\", percentage_of_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_NeVxa0RKWx"
   },
   "source": [
    "### 🕺 Voila! The accuracy on the perturbed set has fallen by 6% with this simple transformation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4qmvF6sQRWu"
   },
   "source": [
    "So what happened internally? --> `execute_model` depending on the transformation type [SentenceOperation](https://github.com/GEM-benchmark/NL-Augmenter/blob/main/interfaces/SentenceOperation.py)) and the task you provided (TEXT_CLASSIFICATION) evaluated a pre-trained model of HuggingFace. In this case, a sentiment analysis model [aychang/roberta-base-imdb](https://huggingface.co/aychang/roberta-base-imdb) was chosen and evaluated on 1% of the [IMDB dataset](https://huggingface.co/datasets/imdb) with and without the transformation to check if the sentiment is predicted correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmOP8B3-TW0i"
   },
   "source": [
    "If you want to evaluate this on your own model and dataset, you can pass the parameters as shown below in the `execute_model` method. Note that we obviously can't support each and every model type and dataset type and hence some models and datasets might require refactoring in the `evaluation_engine` class from your side and we are happy to help. 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKcUmvYzYKAJ"
   },
   "outputs": [],
   "source": [
    "# Here are the different parameters which are used as defaults!\n",
    "# execute_model(MySimpleTransformation, \"TEXT_CLASSIFICATION\", \"en\", model_name = \"aychang/roberta-base-imdb\", dataset=\"imdb\", percentage_of_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHuYXB6OWNiU"
   },
   "source": [
    "##  A Model Based Transformation\n",
    "We don't want to restrict ourselves with just string level changes! We want to do more, don't we? So, let's use a pre-trained paraphrase generator to transform question answering examples. There is an exisiting interface [QuestionAnswerOperation](https://github.com/GEM-benchmark/NL-Augmenter/blob/main/interfaces/QuestionAnswerOperation.py) which takes as input the context, the question and the answer as inputs. Let's use that to augment our training data for question answering! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "a3DehjWXYwnn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "class MySecondTransformation(QuestionAnswerOperation):\n",
    "  tasks = [TaskType.QUESTION_ANSWERING, TaskType.QUESTION_GENERATION]\n",
    "  languages = [\"en\"]\n",
    "\n",
    "  def __init__(self, max_outputs=5):\n",
    "    super().__init__()\n",
    "    model_name=\"prithivida/parrot_paraphraser_on_T5\"\n",
    "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)  \n",
    "    self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    self.max_outputs = max_outputs\n",
    "\n",
    "  def generate(self, context, question, answers): # Note that the choice of inputs for 'generate' is consistent with those in QuestionAnswerOperation\n",
    "    \n",
    "    # Let's call the HF model to generate a paraphrase for the question\n",
    "    paraphrase_input = question\n",
    "    batch = self.tokenizer([paraphrase_input],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\")\n",
    "    translated = self.model.generate(**batch,max_length=60,num_beams=10, num_return_sequences=self.max_outputs, temperature=1.5)\n",
    "    paraphrased_questions = self.tokenizer.batch_decode(translated, skip_special_tokens=True) \n",
    "\n",
    "    # context = \"Apply your own logic here\"\n",
    "    # answers = \"And here too :)\"\n",
    "\n",
    "    # return the list of new question-answering examples\n",
    "    return [(context, paraphrase, answers) for paraphrase in paraphrased_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "18b79a3377bd410084556193d4d80364",
      "ec8d91c84ae04c6a8dbf17ae6cce7c51",
      "0b92079d60954414aaa8c6dd3298b000",
      "5e21a9b42cfc474cbb6b73966cb21917",
      "06342708ba064637af5699d6baac0907",
      "63f92d8c9dda4a70979774825aa270c7",
      "54d9a378c1a64410bb5721c849cbcb9f",
      "2d2d433b9ea442238fbc6cc583eca6a6",
      "dec3bb5dbfd643f3a9087c2e6ec50343",
      "f3f1220356564a56885020393cd64132",
      "e9284b24698b4bedb4d096b9faadc959",
      "6cf9669d4224492fbe946e1f1222a91d",
      "330c8a4fd0da490d9a6e9501c5d84240",
      "5abd033d5ac14c20916f54fc0e1e8ba1",
      "6be6207e6ca94f61bc9cc8ec54b80ef2",
      "3b976142fd274e6e9ff3a3a32491ec94",
      "b356e52fed0143b6bb1b0da1a8cc21a3",
      "4f673d59a91848a6a4ce7bc175e8b95f",
      "5fb1b6153807445dad0a889495ca0902",
      "372bc303a13e4e28a7bf82e4d0a661d4",
      "6c7504fac6be429e811d976271fea613",
      "e41bf03aa90e4922ad4d80a9f8558ced",
      "c9d50c20c5df41598e3e6179e16f9032",
      "75c8b937eb5643ac8674440d415ac402",
      "b16e3c3be9714dd1819f9cac38c46dfe",
      "d91198a8bd74454b88c5befb5ab0753a",
      "8b8f0958e87f4228a7915377f9dd7c96",
      "4218d545a69d410b82194c5b4f5a153c",
      "d0e62835fd624aafb8bfdb8adb20e71e",
      "20727fef4d3b43dbb6c8f560411fecbd",
      "1dcf2fc967b24967a5509911dd6a5e5e",
      "b566613c1952484daea5a277948f7f0d",
      "69f87db5e81043d19ae779ea3144baaf",
      "b44ba94e0a5c49c6ad0bcad1c97b31a6",
      "07ed0ecc612b4e06bdf194db611b5582",
      "53048d9d89fe42c8948ed3d290a16c01",
      "680fdc8baa404f37aaafffb888b47d77",
      "5a95556c568b4c209e525ea5d1dfcf21",
      "9eacdd05ecb8422a8f18559496202e29",
      "ea6e03f570bd4a6fb2fbd85cf43392fd"
     ]
    },
    "id": "84G9YzdGblfP",
    "outputId": "1f9c6695-518e-49c9-f5f1-1d904d6f09f8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b79a3377bd410084556193d4d80364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1373.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec3bb5dbfd643f3a9087c2e6ec50343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b356e52fed0143b6bb1b0da1a8cc21a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1786.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16e3c3be9714dd1819f9cac38c46dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1889.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f87db5e81043d19ae779ea3144baaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891737400.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t4 = MySecondTransformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFY0lGA2lIqy",
    "outputId": "9cdce7db-2098-4044-fccb-f1a5f86c12d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mumbai, Bengaluru, New Delhi are among the many famous places in India.',\n",
       "  'recommend some of the best places to visit in India?',\n",
       "  ['Mumbai', 'Bengaluru', 'Delhi', 'New Delhi']),\n",
       " ('Mumbai, Bengaluru, New Delhi are among the many famous places in India.',\n",
       "  'can you list the best places to visit in India?',\n",
       "  ['Mumbai', 'Bengaluru', 'Delhi', 'New Delhi']),\n",
       " ('Mumbai, Bengaluru, New Delhi are among the many famous places in India.',\n",
       "  'can you list the top 10 places to visit in India?',\n",
       "  ['Mumbai', 'Bengaluru', 'Delhi', 'New Delhi'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.generate(context=\"Mumbai, Bengaluru, New Delhi are among the many famous places in India.\", \n",
    "            question=\"What are the famous places we should not miss in India?\", \n",
    "            answers=[\"Mumbai\", \"Bengaluru\", \"Delhi\", \"New Delhi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOCoNfaV6F9l"
   },
   "source": [
    "Voila! Seems like you have created a new training example now for question-answering and question-generation! 🎉 🎊 🎉 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WF-JtPd6wAm"
   },
   "source": [
    "#Now you are all ready to contribute a transformation to [NL-Augmenter 🦎 → 🐍](https://github.com/GEM-benchmark/NL-Augmenter)! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4e9Y57h0wh-"
   },
   "source": [
    "## What is this deal with filters?\n",
    "So, just the way transformations can transform examples of text, filters can identify whether an example follows some pattern of text! The only difference is that while transformations return another example of the same input format, filters return True or False!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDpDvOjv2Yx9"
   },
   "source": [
    "sentence --> SentenceOperation.**generate**(sentence) --> List of perturbed sentence\n",
    "\n",
    "sentence --> SentenceOperation.**filter**(sentence)  --> TRUE/FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChHoHeq8CGXX"
   },
   "source": [
    "#So, let's play with some existing filters! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfUvpkSN0BKB"
   },
   "outputs": [],
   "source": [
    "from filters.keywords import TextContainsKeywordsFilter\n",
    "from filters.length import TextLengthFilter, SentenceAndTargetLengthFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Le0p5dsBDGA1"
   },
   "source": [
    "The `TextLengthFilter` accepts an input sentence if the length of the input sentence is within the initialised range. Let's initialise this filter to accept all sentences with length greater than 10 tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bb2u3gsE0d_n"
   },
   "outputs": [],
   "source": [
    "f1 = TextLengthFilter(\">\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lK0xTRBsFCdQ",
    "outputId": "24aebfc2-4d58-4278-a049-cdf3d235ec0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.filter(\"This sentence is long enough to pass while you think of implementing your own filter!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diGI4EaOFSun",
    "outputId": "e4f3205d-abbf-4483-e37f-7126410531c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.filter(\"This one's too short!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZMYN4COFiY8"
   },
   "source": [
    "Let's say you have a lot of paraphrasing data and you intend to train a paraphrase generator to convert longer sentences to shorter ones! Check how the `SentenceAndTargetLengthFilter` can be used for this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H27VEe8pFYMl"
   },
   "outputs": [],
   "source": [
    "f2 = SentenceAndTargetLengthFilter([\">\", \"<\"], [10,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ql1ZSsyjG_Y7",
    "outputId": "066fd81f-ac9f-400d-d14d-be26dabdc84b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2.filter(\"That show is going to take place in front of immensely massive crowds.\", \n",
    "          \"Large crowds would attend the show.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKkFIgAtHsB-",
    "outputId": "5f17c054-a00f-4aa2-dc7a-b19b4e719a0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2.filter(\"The film was nominated for the Academy Award for Best Art Direction.\", \n",
    "          \"The movie was a nominee for the Academy Award for Best Art Direction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAScGDfaJKa9"
   },
   "source": [
    "Okay, now that you've said to yourself that these filters are too basic, let's try to make a simple and interesting one! \n",
    "\n",
    "Let's define a filter which selects question-answer pairs which share a low lexical overlap between the question and the context!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7b1mg2ZJcsc"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "class LowLexicalOverlapFilter(QuestionAnswerOperation):\n",
    "  tasks = [TaskType.QUESTION_ANSWERING, TaskType.QUESTION_GENERATION]\n",
    "  languages = [\"en\"]\n",
    "  \n",
    "  def __init__(self, threshold=3):\n",
    "    super().__init__()\n",
    "    self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "    self.threshold = threshold\n",
    "\n",
    "  def filter(self, context, question, answers): \n",
    "    # Note that the only difference between a filter and a transformation is this method! \n",
    "    # The inputs remain the same!\n",
    "    \n",
    "    question_tokenized = self.nlp(question, disable=[\"parser\", \"tagger\", \"ner\"])\n",
    "    context_tokenized = self.nlp(context, disable=[\"parser\", \"tagger\", \"ner\"])\n",
    "    \n",
    "    q_tokens = set([t.text for t in question_tokenized])\n",
    "    c_tokens = set([t.text for t in context_tokenized])\n",
    "    \n",
    "    low_lexical_overlap = len(q_tokens.intersection(c_tokens)) > self.threshold\n",
    "    return low_lexical_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtKYvAr2MbSf"
   },
   "outputs": [],
   "source": [
    "f3 = LowLexicalOverlapFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1np6KirQGZc",
    "outputId": "3cf70a61-266d-4926-c1a5-abae8be318c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3.filter(\"New York, is the most populous city in the United States.\",\n",
    "          \"Which is the most populous city of the United States?\",\n",
    "          [\"New York\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbFOyYHUQVnk",
    "outputId": "d375bde0-6b3d-4717-df21-2c3c46be1a69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3.filter(\"New York, is the most populous city in the United States.\",\n",
    "          \"Which city has the largest population in the US?\",\n",
    "          [\"New York\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE0NY7NKRGfE"
   },
   "source": [
    "That's it!  So you have created a new filter which can separate the hard examples from the easy one! 🎉 🎊 🎉 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKHd2QC_RkwB"
   },
   "source": [
    "#Now go ahead and contribute a nice filter to [NL-Augmenter 🦎 → 🐍](https://github.com/GEM-benchmark/NL-Augmenter)! "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NL-Augmenter  🦎 → 🐍 Write a sample transformation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "NL-Augmenter",
   "language": "python",
   "name": "nl-augmenter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06342708ba064637af5699d6baac0907": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "07ed0ecc612b4e06bdf194db611b5582": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a95556c568b4c209e525ea5d1dfcf21",
      "max": 891737400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_680fdc8baa404f37aaafffb888b47d77",
      "value": 891737400
     }
    },
    "0b92079d60954414aaa8c6dd3298b000": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63f92d8c9dda4a70979774825aa270c7",
      "max": 1373,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06342708ba064637af5699d6baac0907",
      "value": 1373
     }
    },
    "18b79a3377bd410084556193d4d80364": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b92079d60954414aaa8c6dd3298b000",
       "IPY_MODEL_5e21a9b42cfc474cbb6b73966cb21917"
      ],
      "layout": "IPY_MODEL_ec8d91c84ae04c6a8dbf17ae6cce7c51"
     }
    },
    "1dcf2fc967b24967a5509911dd6a5e5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20727fef4d3b43dbb6c8f560411fecbd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d2d433b9ea442238fbc6cc583eca6a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "330c8a4fd0da490d9a6e9501c5d84240": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "372bc303a13e4e28a7bf82e4d0a661d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75c8b937eb5643ac8674440d415ac402",
      "placeholder": "​",
      "style": "IPY_MODEL_c9d50c20c5df41598e3e6179e16f9032",
      "value": " 1.79k/1.79k [00:00&lt;00:00, 1.96kB/s]"
     }
    },
    "3b976142fd274e6e9ff3a3a32491ec94": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4218d545a69d410b82194c5b4f5a153c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b566613c1952484daea5a277948f7f0d",
      "placeholder": "​",
      "style": "IPY_MODEL_1dcf2fc967b24967a5509911dd6a5e5e",
      "value": " 1.89k/1.89k [00:00&lt;00:00, 12.6kB/s]"
     }
    },
    "4f673d59a91848a6a4ce7bc175e8b95f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53048d9d89fe42c8948ed3d290a16c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea6e03f570bd4a6fb2fbd85cf43392fd",
      "placeholder": "​",
      "style": "IPY_MODEL_9eacdd05ecb8422a8f18559496202e29",
      "value": " 892M/892M [00:26&lt;00:00, 33.6MB/s]"
     }
    },
    "54d9a378c1a64410bb5721c849cbcb9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a95556c568b4c209e525ea5d1dfcf21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5abd033d5ac14c20916f54fc0e1e8ba1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e21a9b42cfc474cbb6b73966cb21917": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d2d433b9ea442238fbc6cc583eca6a6",
      "placeholder": "​",
      "style": "IPY_MODEL_54d9a378c1a64410bb5721c849cbcb9f",
      "value": " 1.37k/1.37k [00:02&lt;00:00, 682B/s]"
     }
    },
    "5fb1b6153807445dad0a889495ca0902": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e41bf03aa90e4922ad4d80a9f8558ced",
      "max": 1786,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c7504fac6be429e811d976271fea613",
      "value": 1786
     }
    },
    "63f92d8c9dda4a70979774825aa270c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "680fdc8baa404f37aaafffb888b47d77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "69f87db5e81043d19ae779ea3144baaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_07ed0ecc612b4e06bdf194db611b5582",
       "IPY_MODEL_53048d9d89fe42c8948ed3d290a16c01"
      ],
      "layout": "IPY_MODEL_b44ba94e0a5c49c6ad0bcad1c97b31a6"
     }
    },
    "6be6207e6ca94f61bc9cc8ec54b80ef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c7504fac6be429e811d976271fea613": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6cf9669d4224492fbe946e1f1222a91d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b976142fd274e6e9ff3a3a32491ec94",
      "placeholder": "​",
      "style": "IPY_MODEL_6be6207e6ca94f61bc9cc8ec54b80ef2",
      "value": " 792k/792k [00:01&lt;00:00, 522kB/s]"
     }
    },
    "75c8b937eb5643ac8674440d415ac402": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b8f0958e87f4228a7915377f9dd7c96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20727fef4d3b43dbb6c8f560411fecbd",
      "max": 1889,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0e62835fd624aafb8bfdb8adb20e71e",
      "value": 1889
     }
    },
    "9eacdd05ecb8422a8f18559496202e29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b16e3c3be9714dd1819f9cac38c46dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b8f0958e87f4228a7915377f9dd7c96",
       "IPY_MODEL_4218d545a69d410b82194c5b4f5a153c"
      ],
      "layout": "IPY_MODEL_d91198a8bd74454b88c5befb5ab0753a"
     }
    },
    "b356e52fed0143b6bb1b0da1a8cc21a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fb1b6153807445dad0a889495ca0902",
       "IPY_MODEL_372bc303a13e4e28a7bf82e4d0a661d4"
      ],
      "layout": "IPY_MODEL_4f673d59a91848a6a4ce7bc175e8b95f"
     }
    },
    "b44ba94e0a5c49c6ad0bcad1c97b31a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b566613c1952484daea5a277948f7f0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9d50c20c5df41598e3e6179e16f9032": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0e62835fd624aafb8bfdb8adb20e71e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d91198a8bd74454b88c5befb5ab0753a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dec3bb5dbfd643f3a9087c2e6ec50343": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9284b24698b4bedb4d096b9faadc959",
       "IPY_MODEL_6cf9669d4224492fbe946e1f1222a91d"
      ],
      "layout": "IPY_MODEL_f3f1220356564a56885020393cd64132"
     }
    },
    "e41bf03aa90e4922ad4d80a9f8558ced": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9284b24698b4bedb4d096b9faadc959": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5abd033d5ac14c20916f54fc0e1e8ba1",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_330c8a4fd0da490d9a6e9501c5d84240",
      "value": 791656
     }
    },
    "ea6e03f570bd4a6fb2fbd85cf43392fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec8d91c84ae04c6a8dbf17ae6cce7c51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f1220356564a56885020393cd64132": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
